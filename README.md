Right now I'm deep into **AI-native software development**, rethinking how code gets written when AI agents do the mechanical work. The interesting question isn't whether AI can write code. It's what the job of a software engineer becomes when it can.

## What I'm thinking about

- **Verification as the primary skill** — if AI writes the code, building the system that catches when it's wrong is the actual craft. I wrote about this as [The Dark Software Fabric](https://jw.hn/articles/dark-software-fabric): a 7-layer hierarchy from types to E2E tests that lets autonomous agents ship with confidence.
- **The human role in AI-native workflows**, aka [The Ralph Loop](https://jw.hn/articles/the-ralph-loop) — architecture, intent, and knowing what to verify.
- **Why boring tech wins harder now** — mainstream stacks compound better when your coding partner learned from millions of examples of them.
- **Security of autonomous agents** — prompt injection, containment, treating every AI-touched system as [potentially compromised from day one](https://jw.hn/articles/openclaw).

## Open source

- **[eslint-human-config](https://github.com/JWPapi/eslint-human-config)** — ESLint rules to catch AI-generated slop in copy and design
- **[wt](https://github.com/JWPapi/wt)** — git worktree manager with deterministic dev server ports
- **[trigger-cli](https://github.com/JWPapi/trigger-cli)** — CLI for Trigger.dev: list, search, and run tasks from your terminal

I write longer pieces at [jw.hn](https://jw.hn).
